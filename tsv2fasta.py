from argparse import ArgumentParser
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from pandas import read_csv
from pathlib import Path
from typing import Any


PROG = 'tsv2fasta'
DESCRIPTION = 'Convert tsv results files generated by μProteInS (https://github.com/Eduardo-vsouza/uproteins) into fasta files.'  # noqa: E501
EPILOG = 'The input file will not be validated by the script. Make sure it is a valid μProteInS results file, else the program may crash or fail silently.'  # noqa: E501

parser = ArgumentParser(prog=PROG, description=DESCRIPTION, epilog=EPILOG)   # noqa: E501
parser.add_argument('input', help='input file, should be a results file from μProteInS', type=Path)  # noqa: E501
parser.add_argument('-o', '--output', help='output file name, default is the input file name with fasta extension', type=Path)  # noqa: E501
parser.add_argument('-d', '--dir', help='output directory, default is ./results', default=Path('./results'), type=Path)   # noqa: E501
parser.add_argument('--keep-duplicates', help='if given, the output file will keep the duplicate sequences from the results file', action='store_true')  # noqa: E501


def main(args: dict[str, Any]):
    # Get and validate input path, no need to open the file
    input: Path = args['input']
    if not (input.exists() and input.is_file()):
        parser.error(f'the input is not valid file: {input}')

    # Get the output file name
    output_file: Path | None = args['output']
    if output_file is None:
        output_file = Path(input.with_suffix('.fasta').name)

    # Get and validate the output directory
    output_directory: Path = args['dir']
    try:
        output_directory.mkdir(exist_ok=True)
    except FileExistsError as e:
        parser.error(e)

    output_path = output_directory.joinpath(output_file)

    duplicates = args['keep_duplicates']
    with open(output_path, 'w') as output:
        SeqIO.write(to_SeqRecord_stream(input, duplicates), output, 'fasta')


def to_SeqRecord_stream(input, duplicates):
    # SeqIO.write() requires an iterator[SeqRecord], so this function converts
    # the input file to a Pandas dataFrame and yields SeqRecords from it
    table = read_csv(
        input,
        sep='\t',
    ).rename(columns=lambda name: name.replace(' ', '_'))
    # Make sure field names are valid Python identifiers

    # Remove duplicates if --keep-duplicates wasn't passed
    if not duplicates:
        table.drop_duplicates(
            subset=['Genome_Coordinates', 'Protein_sequence'],
            inplace=True,
        )

    for item in table.itertuples():
        yield SeqRecord(
            id=f'{item.ORF_name}_{item.Genome_Coordinates}.{item.Index}',
            seq=Seq(item.Protein_sequence),
            description=f'file {item.SpecFile}; '
                        f'scanNum {item.ScanNum}; '
                        f'peptide {item.Peptide}',
        )


if __name__ == '__main__':
    main(vars(parser.parse_args()))
